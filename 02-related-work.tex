The Louvain method, introduced by Blondel et al. \cite{com-blondel08} from the University of Louvain, is a greedy modularity-optimization based algorithm for community detection \cite{com-lancichinetti09}. While it is favored for identifying communities with high modularity, it often results in internally disconnected communities. This occurs when a vertex, acting as a bridge, moves to another community during iterations. Further iterations aggravate the problem, without decreasing the quality function. Further, the Louvain method may identify communities that are not well connected, i.e., splitting certain communities could improve the quality score --- such as modularity \cite{com-traag19}.\ignore{This is not the same as resolution limit problem with modularity, that causes small communities to be clustered with large communities. Louvain only guarantees that no communities can be merged (well separated).}

To address these limitations, Traag et al. \cite{com-traag19} from the University of Leiden, propose the Leiden algorithm\ignore{as an enhancement of the Louvain method}. It introduces a \textit{refinement phase} after the local-moving phase, where vertices within each community undergo constrained merges in a randomized fashion proportional to the delta-modularity of the move. This allows vertices to find sub-communities within those obtained from the local-moving phase. The Leiden algorithm guarantees that the identified communities are both well separated (like the Louvain method) and well connected. When communities have converged, it is guaranteed that all vertices are optimally assigned, and all communities are subset optimal \cite{com-traag19}. Shi et al. \cite{com-shi21} also introduce an additional refinement phase after the local-moving phase with the Louvain method, which they observe minimizes bad clusters. It should however be noted that methods relying on modularity maximization are known to suffer from resolution limit problem, which prevents identification of communities of certain sizes \cite{com-ghosh19, com-traag19}. This can be overcome by using an alternative quality function, such as the Constant Potts Model (CPM) \cite{com-traag11}.

We now discuss a number of algorithmic improvements proposed for the Louvain method, that also apply to the Leiden algorithm. These include ordering of vertices based on importance \cite{com-aldabobi22}, attempting local move only on likely vertices \cite{com-ryu16, com-zhang21, com-shi21}\ignore{\cite{com-ozaki16}}, early pruning of non-promising candidates\ignore{(leaf vertices)} \cite{com-ryu16, com-halappanavar17, com-zhang21, com-you22}, moving vertices to a random neighbor community \cite{com-traag15}, subnetwork refinement \cite{com-waltman13, com-traag19}, multilevel refinement \cite{com-rotta11, com-gach14, com-shi21}, threshold cycling \cite{com-ghosh18}, threshold scaling \cite{com-lu15, com-naim17, com-halappanavar17}, and early termination \cite{com-ghosh18}. A number of parallelization techniques have been also attempted for the Louvain method, that may also be applied to the Leiden algorithm. These include\ignore{using heuristics to break the sequential barrier \cite{com-lu15},} using adaptive parallel thread assignment \cite{com-fazlali17, com-naim17, com-sattar19, com-mohammadi20}, parallelizing the costly first iteration \cite{com-wickramaarachchi14}, ordering vertices via graph coloring \cite{com-halappanavar17}, performing iterations asynchronously \cite{com-shi21}\ignore{\cite{com-que15}}\ignore{, using vector based hashtables \cite{com-halappanavar17}}, and using sort-reduce instead of hashing \cite{com-cheong13}\ignore{, using simple partitions based of vertex ids \cite{com-cheong13, com-ghosh18}, and identifying and moving ghost/doubtful vertices \cite{com-zeng15, com-que15, com-bhowmik19, com-bhowmick22}}.\ignore{Platforms used range from an AMD multicore system \cite{com-fazlali17}, and Intelâ€™s Knight's Landing, Haswell \cite{com-gheibi20}, SkylakeX, and Cascade Lake \cite{part-hossain21}. Other approaches include the use of MapReduce in a BigData batch processing framework \cite{com-zeitz17}.}

A few open source implementations and software packages have been developed for community detection using Leiden algorithm. The original implementation of the Leiden algorithm \cite{com-traag19}, called \texttt{libleidenalg}, is written in C++ and has a Python interface called \texttt{leidenalg}. NetworKit \cite{staudt2016networkit} is a software package designed for analyzing the structural aspects of graph data sets with billions of connections. It utilizes a hybrid with C++ kernels and a Python frontend. The package features a parallel implementation of the Leiden algorithm by Nguyen \cite{nguyenleiden} which uses global queues for vertex pruning, and vertex and community locking for updating communities. igraph \cite{csardi2006igraph} is a similar package, written in C, with Python, R, and Mathematica frontends. It is widely used in academic research, and includes an implementation of the Leiden algorithm. cuGraph \cite{kang2023cugraph} is a GPU-accelerated graph analytics library, part of the RAPIDS suite of data science and machine learning libraries. It leverages the computational power of NVIDIA GPUs to perform graph analytics tasks much faster than traditional CPU-based approaches. cuGraph's core is implemented in C++ with CUDA and is used primarily through its Python interface, making it convenient for data scientists and developers\ignore{working in Python}.
% I see two thesis by Fabian, Karlsruhe Institute of Technology and Magnus, University of Bergen. Fabian uses global queues and for vertex pruning, and vertex and community locking for updating communities, which is likely to be less efficient. Magnus uses the same approach as Fabien. On europe graph their algorithm takes 60-70s with 64 threads (on a 128 core system).

However, most existing works only focus on optimizing the local-moving phase of Leiden algorithm, are not sufficiently optimized, and are either sequential or lack effective parallelization. For instance, the \textit{original Leiden} implementation \cite{com-traag19}\ignore{, \textit{libleidenalg}}, uses a full \texttt{Graph} data structure for each of the collapsed graphs without reuse and makes a complete copy of the communities when collapsing the graph. Further, it tracks the community membership of vertices in each dendrogram layer, adding to the computational overhead. Additionally, it employs a queue and a flag vector to monitor the nodes to be moved in each iteration, with the processing order randomly shuffled. A new degree vector is allocated in each iteration, and community memberships are renumbered after each local-moving and refinement phase. This implementation also conducts several book-keeping activities when moving a node to another community, such as maintaining community sets, removing empty communities, and updating the total edge weight from communities. Finally, it also  keeps track of nodes with fixed community memberships using three vectors, a process repeated in each local-moving phase.

The \textit{igraph Leiden} implementation \cite{csardi2006igraph} follows a comparable approach but with some differences that streamline its operations slightly. Like the original Leiden, it uses a full \texttt{Graph} data structure for each collapsed graph without reuse. igraph Leiden also uses a queue and a flag vector to manage nodes during the local-moving phase, with the processing order randomly shuffled as well. In addition, it also reindexes the community membership of vertices after the local-moving phase, and the refinement phase also involves a random node shuffling. However, unlike the original Leiden, igraph only maintains the size of each community rather than the individual nodes, simplifying the process. Unlike the original Leiden, it does not track edge weights from communities but instead keeps track of total edge weights, which is easier to manage.

The \textit{NetworKit Leiden} implementation \cite{staudt2016networkit} introduces parallel processing but retains some of the complexity seen in the above implementations. It uses a queue and a flag vector to track vertices for processing, incorporating a mutex and a condition variable for parallel access and updates, with node shuffling done on a single thread. Synchronization between threads is performed to manage available work, while employing locks. During the aggregation phase, not all operations are parallelized, such as the prefix sum calculation. Community membership of vertices is tracked and flattened at the end, while node mapping is stored in a \texttt{std::map}, and fine to coarse mapping is sequentially stored. These issues\ignore{, along with non-parallelized aggregation tasks,} contribute to the computational expense of NetworKit Leiden, despite the benefits of parallel processing.
